{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Syntax\n",
    "\n",
    "### Natural Language Processing and Information Extraction,  2023 WS\n",
    "Lecture 6, 11/17/2023\n",
    "\n",
    "Gábor Recski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This material can be downloaded from\n",
    "\n",
    "[https://github.com/tuw-nlp-ie/tuw-nlp-ie-2023WS](https://github.com/tuw-nlp-ie/tuw-nlp-ie-2023WS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Topics and SLP3 chapters\n",
    "\n",
    "- Parts-of-speech: [Chapter 8](https://web.stanford.edu/~jurafsky/slp3/8.pdf)\n",
    "\n",
    "- Constituency: [Chapter 17](https://web.stanford.edu/~jurafsky/slp3/17.pdf)\n",
    "\n",
    "- Dependency: [Chapter 18](https://web.stanford.edu/~jurafsky/slp3/18.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dependencies\n",
    "\n",
    "To run this notebook, you will need to install the **stanza** and **spacy** python packages.\n",
    "\n",
    "Make sure to restart the kernel afterwards.\n",
    "\n",
    "Then you can use the cells below to download and initialize the necessary models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Download models, initialize pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090af7a1a5d04cfb8ad103951c23e86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/res…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 12:50:45 INFO: Downloading default packages for language: en (English) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 12:50:46 INFO: File exists: /home/recski/stanza_resources/en/default.zip\n",
      "2023-11-17 12:50:51 INFO: Finished downloading models and saved to /home/recski/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('en')\n",
    "stanza_nlp = stanza.Pipeline(lang='en', logging_level='WARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en-core-web-sm==3.7.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (3.7.1)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1; python_version < \"3.8\" in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.3)\n",
      "Requirement already satisfied: jinja2 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.3)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0; python_version < \"3.9\" in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.21.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.8.2)\n",
      "Requirement already satisfied: setuptools in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (50.3.0.post20201006)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.6)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.50.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
      "Requirement already satisfied: confection<0.2.0,>=0.0.4 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.2)\n",
      "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.8.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: importlib_metadata; python_version < \"3.8\" in /home/recski/miniconda3/envs/nlp_course/lib/python3.7/site-packages (from cloudpathlib<0.16.0,>=0.7.0->weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.cli import download as spacy_download\n",
    "spacy_download('en_core_web_sm')\n",
    "spacy_nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Tokenization, lemmatization, decompounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did     \tdo\n",
      "you     \tyou\n",
      "get     \tget\n",
      "me      \tI\n",
      "those   \tthat\n",
      "muffins \tmuffin\n",
      "?       \t?\n"
     ]
    }
   ],
   "source": [
    "doc = stanza_nlp(\"Did you get me those muffins?\")\n",
    "print(\"\\n\".join([f\"{word.text:<8}\\t{word.lemma}\" for word in doc.sentences[0].words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "```\n",
    "Twas brillig, and the slithy toves\n",
    "Did gyre and gimble in the wabe;\n",
    "All mimsy were the borogoves,\n",
    "And the mome raths outgrabe.\n",
    "```\n",
    "(Lewis Carroll: [Jabberwocky](https://en.wikipedia.org/wiki/Jabberwocky))\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "Es brillig war. Die schlichten Toven\n",
    "Wirrten und wimmelten in Waben;\n",
    "Und aller-mümsige Burggoven\n",
    "Die mohmen Räth' ausgraben.\n",
    "```\n",
    "(Translated by Robert Scott)\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "They don't make much sense, but how come they make any?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part-of-speech (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did     \tAUX\n",
      "you     \tPRON\n",
      "get     \tVERB\n",
      "me      \tPRON\n",
      "those   \tDET\n",
      "muffins \tNOUN\n",
      "?       \tPUNCT\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([f\"{word.text:<8}\\t{word.pos}\" for word in doc.sentences[0].words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did     \tVBD\n",
      "you     \tPRP\n",
      "get     \tVB\n",
      "me      \tPRP\n",
      "those   \tDT\n",
      "muffins \tNNS\n",
      "?       \t.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([f\"{word.text:<8}\\t{word.xpos}\" for word in doc.sentences[0].words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### POS-tags are morphosyntactic categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| Word | [UPOS](https://universaldependencies.org/u/pos/) |  | [PTB](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) | |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| Did | AUX | auxiliary | VBD | verb, past tense |\n",
    "| you | PRON | pronoun | PRP | personal pronoun |\n",
    "| get | VERB | verb | VB | verb, base form |\n",
    "| me | PRON | pronoun | PRP | personal pronoun |\n",
    "| those | DET | determiner | DT | determiner |\n",
    "| muffins | NOUN | noun | NNS | noun, plural |\n",
    "| ? | PUNCT | punctuation | . | punctuation |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There's always more morphosyntactic features to consider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did     \tAUX     \tMood=Ind|Number=Sing|Person=2|Tense=Past|VerbForm=Fin\n",
      "you     \tPRON    \tCase=Nom|Person=2|PronType=Prs\n",
      "get     \tVERB    \tVerbForm=Inf\n",
      "me      \tPRON    \tCase=Acc|Number=Sing|Person=1|PronType=Prs\n",
      "those   \tDET     \tNumber=Plur|PronType=Dem\n",
      "muffins \tNOUN    \tNumber=Plur\n",
      "?       \tPUNCT   \tNone\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([f\"{word.text:<8}\\t{word.pos:<8}\\t{word.feats}\" for word in doc.sentences[0].words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Difficulties of POS-tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_earnings growth took a __back/JJ__ seat_\n",
    "\n",
    "_a small building in the **back/NN**_\n",
    "\n",
    "_a clear majority of senators **back/VBP** the bill_\n",
    "\n",
    "_Dave began to __back/VB__ toward the door_\n",
    "\n",
    "_enable the country to buy __back/RP__ about debt_\n",
    "\n",
    "_I was twenty-one __back/RB__ then_\n",
    "\n",
    "([SLP Ch.8](https://web.stanford.edu/~jurafsky/slp3/8.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why not implement grammar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- grammar and vocabulary change too fast\n",
    "\n",
    "- resolving ambiguities requires probabilistic reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "| _Time_ | _flies_ | _like_ | _an_ | _arrow_ |\n",
    "| :----- | :------ | :----- | :--- | :------ |\n",
    "| NOUN   | VERB    | ADP    | DET  | NOUN    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| _Time_ | _flies_ | _like_ | _an_ | _arrow_ |\n",
    "| :----- | :------ | :----- | :--- | :------ |\n",
    "| VERB   | NOUN    | ADP    | DET  | NOUN    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| _Time_ | _flies_ | _like_ | _an_ | _arrow_ |\n",
    "| :----- | :------ | :----- | :--- | :------ |\n",
    "| NOUN   | NOUN    | VERB   | DET  | NOUN    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "BTW: the second one can still have three interpretations - can you think of all of them (without googling)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "See the supplementary material in `06b_POS_tagging_HMMs.ipynb` on POS-tagging with Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Syntactic structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Two perspectives\n",
    "\n",
    "- Constituency structure\n",
    "\n",
    "- Dependency structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Constituency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## I shot an elephant in my pyjamas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I           PRON\n",
      "shot        VERB\n",
      "an          DET\n",
      "elephant    NOUN\n",
      "in          ADP\n",
      "my          PRON\n",
      "pyjamas     NOUN\n"
     ]
    }
   ],
   "source": [
    "doc = stanza_nlp(\"I shot an elephant in my pyjamas\")\n",
    "print(\"\\n\".join([f\"{word.text:<12}{word.pos}\" for word in doc.sentences[0].words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![elephant](elephant.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![NP](np2_70.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> (NP <br/>\n",
    "> $\\quad$ (DET an) <br/>\n",
    "> $\\quad$ (Nominal <br/>\n",
    "> $\\quad \\quad$ (Nominal <br/>\n",
    "> $\\quad \\quad \\quad$ (NOUN elephant) <br/>\n",
    "> $\\quad \\quad$ ) <br/>\n",
    "> $\\quad$ (PP <br/>\n",
    "> $\\quad \\quad$ (PREP in) <br/>\n",
    "> $\\quad \\quad$ (NP <br/>\n",
    "> $\\quad \\quad \\quad$ (DET my) <br/>\n",
    "> $\\quad \\quad \\quad$ (NOUN pyjamas) <br/>\n",
    "> $\\quad \\quad$ ) <br/>\n",
    "> $\\quad $ ) <br/>\n",
    "> )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### NP, PP, etc. are distributional categories. Just like POS-tags!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(DET an) (NOUN elephant) (PREP in) (DET my) (NOUN pyjamas)\n",
    "\n",
    "(DET two) (NOUN pandas) (PREP behind) (DET his) (NOUN tent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(NP I) (VERB shot) (NP an elephant) (PP in my pyjamas)\n",
    "\n",
    "(NP My best friend) (VERB met) (NP two pandas) (PP behind his tent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(NP I) (VP shot an elephant in my pyjamas)\n",
    "\n",
    "(NP The guy driving the jeep) (VP fainted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Phrase structure grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "S -> NP VP\n",
    "VP -> VERB (NP)\n",
    "NP -> (DET) NOUN (PP)\n",
    "PP -> PREP NP\n",
    "(...)\n",
    "DET -> (an|the|my|his|...)\n",
    "VERB -> (shot|met|fainted...)\n",
    "PREP -> (in|behind|...)\n",
    "NOUN -> (I|elephant|pyjamas|panda|tent|jeep|guy|...)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probabilistic grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "NOUN -> I (0.8)\n",
    "NOUN -> elephant (0.1)\n",
    "(...)\n",
    "VP -> VERB (0.2)\n",
    "VP -> VERB NP (0.8)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Constituency parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Parsing is the task of determining the (most likely) possible derivations of a sentence, given a (probabilistic) grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### The CKY algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "See example in [cky.pdf](cky.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dependency structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![dep1](dep1.jpg)\n",
    "![dep2](dep2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- **NSUBJ**: nominal subject\n",
    "- **OBJ**: object\n",
    "- **DET**: determiner\n",
    "- **OBL**: oblique nominal\n",
    "- **NMOD**: nominal modifier\n",
    "- **POSS**: possessive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   I           nsubj       2       \n",
      "2   shot        root        0       \n",
      "3   an          det         4       \n",
      "4   elephant    obj         2       \n",
      "5   in          case        7       \n",
      "6   my          nmod:poss   7       \n",
      "7   pyjamas     obl         2       \n"
     ]
    }
   ],
   "source": [
    "doc = stanza_nlp(\"I shot an elephant in my pyjamas\")\n",
    "print(\"\\n\".join([f\"{word.id:<4}{word.text:<12}{word.deprel:<12}{word.head:<8}\" for word in doc.sentences[0].words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dependency parsing - approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Arc-factored parsing\n",
    "- model the likelihood of edges\n",
    "- e.g. how likely is _nmod(elephant, pyjamas)_?\n",
    "- find the dependency graph with the most likely edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Transition-based parsing\n",
    "- build dependency graphs by adding one word at a time\n",
    "- model the likelihood of possible next steps\n",
    "- e.g. should I attach _pyjamas_ to _elephant_ or _shot_?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shift-reduce parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![shiftreduce](shiftreduce.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Shift-reduce parsing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- transition-based approach\n",
    "- processes words one-by-one, in linear order, no backtracking\n",
    "\n",
    "- for each word, choose between:\n",
    "    - **shift**: push the next word on the **stack**\n",
    "    - **reduce**: add a dependency edge between the top two words on the stack, and remove the dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shift-reduce example\n",
    "\n",
    "See [shiftreduce.pdf](shiftreduce.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A historical note on the two perspectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Constituency structure\n",
    "- Origins in **structural linguistics** (F. de Saussure, 1900s and later L. Bloomfield, 1930s)\n",
    "- (The basic ideas actually date back to **Pāṇini** (~500 BCE))\n",
    "- Application of **formal language theory** (e.g. PS grammars) in 1950s (N. Chomsky)\n",
    "- Remains the mainstream perspective in theoretical linguistics (known as **generative grammar**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Dependency structure\n",
    "- Origins in **Dependency grammar** (Tesnière, 1950s)\n",
    "- (The basic ideas actually date back to **Pāṇini** (~500 BCE))\n",
    "- Widespread use in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
